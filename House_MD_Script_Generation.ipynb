{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "House MD Text Generation New.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIjAIzHNTs6G",
        "colab_type": "text"
      },
      "source": [
        "### **Mounting To Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_50Soo03cJY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVZGHd1sT2bw",
        "colab_type": "text"
      },
      "source": [
        "### **Importing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3gIv2iB2SDL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6eFM5LuVTq_",
        "colab_type": "text"
      },
      "source": [
        "### **Read in the text corpus**\n",
        "This text corpus was built by scraping the transcripts from the site:\n",
        "https://clinic-duty.livejournal.com/12225.html. The data was then cleaned by removing non-ascii characters, blank lines, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjP6w2hL3v0V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/House MD Text Generation/Final Merged UTF8 SymbolCorrected.txt','r',encoding = \"utf8\") as f:\n",
        "  text = f.read().lower().replace('\\n',' \\n ')\n",
        "print(text[:2000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ucgLdGH72kk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = [w for w in text.split(' ') if w != '']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaJN38aHP4jB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words[0:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZ-d4O7w8w7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4r7drVrVvNB",
        "colab_type": "text"
      },
      "source": [
        "### **Store word frequencies in a dictionary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMzZqVYdBOwB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_frequencies = {}\n",
        "for word in words:\n",
        "    word_frequencies[word] = word_frequencies.get(word, 0) + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lt25eVkWWAnE",
        "colab_type": "text"
      },
      "source": [
        "### **Remove infrequent words from corpus**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bx7rxZuPDZJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "min_frequency = 10\n",
        "ignored_words = set()\n",
        "for k,v in word_frequencies.items():\n",
        "  if word_frequencies[k] < min_frequency:\n",
        "    ignored_words.add(k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnqhBcLxb882",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(ignored_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiHfFRzUShMD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_values_from_list(the_list, ignored_words):\n",
        "   return [value for value in the_list if value not in ignored_words]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5cm5SReSjAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = remove_values_from_list(words,ignored_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVPhXrHPU58p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUSrWJduY4dI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(set(words))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2F5y0FPck89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_edited = ' '.join(words)\n",
        "with open(\"/content/drive/My Drive/House MD Text Generation/House Edited Frequency and Symbols.txt\",'w') as file:\n",
        "  file.write(text_edited)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXR1M9G4WuN-",
        "colab_type": "text"
      },
      "source": [
        "### **Create vectorization dictionaries and vectorize the corpus**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91u2AjB9P89G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_indices = dict((word, index) for index, word in enumerate(set(words)))\n",
        "indices_word = dict((index, word) for index, word in enumerate(set(words)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzhTpFtZQRh_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorized_words = []\n",
        "for word in words:\n",
        "    vectorized_words.append(word_indices[word])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZYfBSE5WmGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorized_words = np.array(vectorized_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WPB3UBZL45y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorized_words.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3LL6aUFL_qt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorized_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9v9ZU3ZXo2o",
        "colab_type": "text"
      },
      "source": [
        "### **Create sequences of words**\n",
        "Here the window size is 50. Sentences and their corresponding next words are stored in X_train and y_train respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7o0yriaeYUHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Hyperparameters definition\n",
        "seq_length = 50\n",
        "batch_size = 100\n",
        "learning_rate = 0.001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpqHl-gKMPTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "for i in range(seq_length,len(vectorized_words)):\n",
        "  X_train.append(vectorized_words[i-seq_length:i])\n",
        "  y_train.append(vectorized_words[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiePF38UZ33h",
        "colab_type": "text"
      },
      "source": [
        "### **Custom batch generator**\n",
        "Due to the size of the corpus, we cannot load the entire set of sequences into memory at once as this will result in a crash. Therefore, we build a custom generator to yield batches during the fit call."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbj62BIv5vQ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batch(vectorized_words, seq_length, batch_size):\n",
        "  n = vectorized_words.shape[0] - 1\n",
        "  while True:    \n",
        "    idx = np.random.choice(n-seq_length, batch_size)\n",
        "    input_batch = [vectorized_words[i : i+seq_length] for i in idx]\n",
        "    output_batch = [vectorized_words[i+seq_length+1] for i in idx]\n",
        "    x_batch = np.reshape(input_batch, [batch_size, seq_length])\n",
        "    y_batch = tf.keras.utils.to_categorical(output_batch,num_classes = len(set(words)))\n",
        "    yield x_batch, y_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOrwIKsYQ0Oe",
        "colab_type": "text"
      },
      "source": [
        "### **Model Structure**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0jJnLmO2kCX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(batch_size):\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Embedding(input_dim = len(set(words)),output_dim = 128,input_length = seq_length))\n",
        "  model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256,input_shape=(seq_length, len(set(words))))))\n",
        "  model.add(tf.keras.layers.Dense(len(set(words))))\n",
        "  model.add(tf.keras.layers.Activation('softmax'))\n",
        "  model.compile(optimizer = tf.keras.optimizers.Adam(lr = learning_rate), loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0raDjqxvl25",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model(batch_size)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8QsxCxtQ_zM",
        "colab_type": "text"
      },
      "source": [
        "### **Load pretrained weights if any (for further training) and fit the model**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kl55qt6NYjc3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "load_path = \"/content/drive/My Drive/house_weights_50-100-200000.hdf5\"\n",
        "if load_path != '':\n",
        "  model.load_weights(load_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BSFXn_MwrKZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "import os\n",
        "import datetime\n",
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "checkpoint = \"/content/drive/My Drive/House MD Text Generation/\"\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint,monitor = 'accuracy',save_best_only = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yV32zdyTzlOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "steps_per_epoch = 1000\n",
        "%tensorboard --logdir logs\n",
        "history = model.fit(get_batch(vectorized_words, seq_length, batch_size),steps_per_epoch = steps_per_epoch,epochs = 500,verbose = 1,callbacks=[tensorboard_callback,model_checkpoint])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NcRh2-ilBMY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62aGX8pNfhZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_path = \"/content/drive/My Drive/house_weights_{}-{}-{}-second.hdf5\".format(seq_length,batch_size,steps_per_epoch)\n",
        "model.save_weights(save_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tM2aCf23RUWF",
        "colab_type": "text"
      },
      "source": [
        "### **Build the predictor**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7Hi75yPf8pQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_predict = build_model(1)\n",
        "model_predict.load_weights(save_path)\n",
        "model_predict.save('/content/drive/My Drive/model-predict-second.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtP40vOjgER9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_predict.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f630cutRbgI",
        "colab_type": "text"
      },
      "source": [
        "### **Helper Function**\n",
        "This is a function taken from the Keras example and it basically helps to add randomness to the text generation process. Otherwise, the generated text can get repetitive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MbQcyLfXDop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGrKEvZyRvt2",
        "colab_type": "text"
      },
      "source": [
        "### **The Text Generator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCc5NqWGXH3L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model, prompt_string, gen_len = 100,temperature = 0.45):\n",
        " \n",
        "  prompt_string = prompt_string.lower()  \n",
        "  input = []\n",
        "  for word in prompt_string.split(\" \"):\n",
        "    if word != '':\n",
        "      try:\n",
        "        input.append(word_indices[word])\n",
        "      except KeyError:\n",
        "        input.append(np.random.randint(0,len(set(words))))\n",
        "  input = tf.keras.preprocessing.sequence.pad_sequences([input], maxlen=seq_length, padding = \"post\",truncating = \"pre\",value = np.random.randint(0,len(set(words))))\n",
        " \n",
        "  generated = prompt_string\n",
        "  for i in range(gen_len): \n",
        "    preds = model.predict(input, verbose=0)[0]\n",
        "    next_index = sample(preds, temperature)\n",
        "    next_word = indices_word[next_index]\n",
        "    generated += \" \" + next_word\n",
        "    input= np.append(input,next_index)\n",
        "    input = input[1:]\n",
        "    \n",
        "  return generated"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ki_RaHPVjILd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = generate_text(model_predict, 'wilson:', gen_len = 100,temperature = 0.65)\n",
        "text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgexxo3vR1Fr",
        "colab_type": "text"
      },
      "source": [
        "### **Name Capitalization**\n",
        "Since all words in our corpus are converted to lowercase while training, we need to capitalize the names in the ouput text. For this, the entire list of character names was scraped from the IMDb site on House M.D. and saved to a file. The capitalize_names function checks for names and returns the desired output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93y-P4nK2UWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"/content/drive/My Drive/House MD Text Generation/Names-List.pkl\",\"rb\") as f:\n",
        "  names_list = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zGp49osQnV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def capitalize_names(text):\n",
        "  final_output = []\n",
        "  for word in text.split(\" \"):\n",
        "    if word in names_list or word[:-1] in names_list:\n",
        "      final_output.append(word[0].upper()+word[1:])\n",
        "    else:\n",
        "      final_output.append(word)\n",
        "  return ' '.join(final_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqRhuM55SRbc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = capitalize_names(text)\n",
        "text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QJW4Fm_xrMU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}